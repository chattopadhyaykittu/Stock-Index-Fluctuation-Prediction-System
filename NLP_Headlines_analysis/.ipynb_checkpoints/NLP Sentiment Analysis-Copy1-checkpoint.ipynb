{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sreer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import libraries and modules\n",
    "#from google.colab import files\n",
    "import io\n",
    "import pandas as pd\n",
    "#Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "#NLP packages\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "punc = string.punctuation\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Supervised learning\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "##Deep learning libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    4999 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#uplaod the data from your local directory\n",
    "#uploaded = files.upload()\n",
    "# store the dataset as a Pandas Dataframe\n",
    "df = pd.read_csv(r\"C:\\Users\\sreer\\Big data project\\Headlines_5000.csv\")\n",
    "#conduct some data cleaning\n",
    "df = df.drop(['date','time_12hr','time_24hr','category'], axis=1)\n",
    "df = df.rename(columns = {'headline': 'text'})\n",
    "df['text'] = df['text'].astype(str)\n",
    "#check the data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia-Ukraine war LIVE updates: NATO leaders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNBC-TV18 Classroom: What should be your optio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ukraine-Russia conflict: From sunflower oil to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IOC to be dropped from Nifty 50 from March 31;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBI says NSE Himalayan yogi none other than An...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Russia-Ukraine war LIVE updates: NATO leaders ...\n",
       "1  CNBC-TV18 Classroom: What should be your optio...\n",
       "2  Ukraine-Russia conflict: From sunflower oil to...\n",
       "3  IOC to be dropped from Nifty 50 from March 31;...\n",
       "4  CBI says NSE Himalayan yogi none other than An..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Labels using Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants to represent the class labels :positive, negative, and abstain\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "#define function which looks into the input words to represent a proper label\n",
    "def keyword_lookup(x, keywords, label):  \n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "#define function which assigns a correct label\n",
    "def make_keyword_lf(keywords, label=POSITIVE):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))\n",
    "#resource: https://www.snorkel.org/use-cases/01-spam-tutorial#3-writing-more-labeling-functions\n",
    "#these two lists can be further extended \n",
    "\"\"\"positive news might contain the following words' \"\"\"\n",
    "keyword_positive = make_keyword_lf(keywords=['boosts', 'great', 'develops', 'promising', 'ambitious', 'delighted', 'record', 'win', 'breakthrough', 'recover', 'achievement', 'peace', 'party', 'hope', 'flourish', 'respect', 'partnership', 'champion', 'positive', 'happy', 'bright', 'confident', 'encouraged', 'perfect', 'complete', 'assured' ])\n",
    "\"\"\"negative news might contain the following words\"\"\"\n",
    "keyword_negative = make_keyword_lf(keywords=['war','solidiers', 'turmoil', 'injur','trouble', 'aggressive', 'killed', 'coup', 'evasion', 'strike', 'troops', 'dismisses', 'attacks', 'defeat', 'damage', 'dishonest', 'dead', 'fear', 'foul', 'fails', 'hostile', 'cuts', 'accusations', 'victims',  'death', 'unrest', 'fraud', 'dispute', 'destruction', 'battle', 'unhappy', 'bad', 'alarming', 'angry', 'anxious', 'dirty', 'pain', 'poison', 'unfair', 'unhealthy'\n",
    "                                              ], label=NEGATIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TextBlob to get polarity and subjectivity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a preprocessor function to determine polarity & subjectivity using textlob pretrained classifier \n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "#find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return POSITIVE if x.polarity > 0.6 else ABSTAIN\n",
    "#find subjectivity \n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return POSITIVE if x.subjectivity >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all the labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreer\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4999/4999 [00:14<00:00, 336.56it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|                                                                                       | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.019]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=0.007]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=0.000]\n",
      " 31%|███████████████████████▊                                                     | 31/100 [00:00<00:00, 295.23epoch/s]INFO:root:[40 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.000]\n",
      " 68%|████████████████████████████████████████████████████▎                        | 68/100 [00:00<00:00, 311.12epoch/s]INFO:root:[70 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=0.000]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 341.30epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "#combine all the labeling functions \n",
    "lfs = [keyword_positive, keyword_negative, textblob_polarity, textblob_subjectivity ]\n",
    "#apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "#apply the label model\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "#fit on the data\n",
    "label_model.fit(L_snorkel)\n",
    "#predict and create the labels\n",
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1929\n",
       "0     136\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering out unlabeled data points\n",
    "df= df.loc[df.label.isin([0,1]), :]\n",
    "#find the label counts \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreer\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1b936679594cd999db1e9675e5bc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2065.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreer\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27982f05d3c94c8f8fc988e4508996b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2065.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#make a copy of the dataframe\n",
    "data = df.copy()\n",
    "#define a function which handles the text preprocessing \n",
    "def preparation_text_data(data):\n",
    "    \"\"\"\n",
    "    This pipeline prepares the text data, conducting the following steps:\n",
    "    1) Tokenization\n",
    "    2) Lemmatization\n",
    "    4) Removal of stopwords\n",
    "    5) Removal of punctuation\n",
    "    \"\"\"\n",
    "    # initialize spacy object\n",
    "    nlp = en_core_web_sm.load()\n",
    "    # select raw text\n",
    "    raw_text = data.text.values.tolist()\n",
    "    # tokenize\n",
    "    tokenized_text = [[nlp(i.lower().strip())] for i in tqdm(raw_text)]\n",
    "    #define the punctuations and stop words\n",
    "    punc = string.punctuation \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #lemmatize, remove stopwords and punctuationd\n",
    "    corpus = []\n",
    "    for doc in tqdm(tokenized_text):\n",
    "        corpus.append([word.lemma_ for word in doc[0] if (word.lemma_ not in stop_words and word.lemma_ not in punc)])\n",
    "    # add prepared data to df\n",
    "    data[\"text\"] = corpus\n",
    "    return data\n",
    "#apply the data preprocessing function\n",
    "data =  preparation_text_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2065, 3049)\n",
      "['000', '016', '02', '024', '028', '031', '050', '065', '08', '10', '100', '10gm', '11', '110', '112', '113', '115', '119', '12', '124', '125', '13', '135', '14', '140', '143', '145', '148', '15', '150', '153', '155', '157', '16', '162', '1680', '169', '17', '170', '18', '187', '18k', '19', '190', '197', '198', '1999', '1st', '20', '200', '2007', '2014', '2016', '2018', '2019', '2020', '2021', '2022', '2023', '207', '2077', '2078', '21', '22', '220', '221', '23', '233', '24', '246', '25', '250', '26', '260', '262', '265', '27', '270', '28', '29', '296', '2nd', '30', '300', '304', '31', '32', '325', '329', '33', '330', '34', '35', '350', '352', '36', '37', '38', '381', '385', '3rd', '3x', '40', '400', '40000', '405', '41', '410', '42', '420', '43', '44', '45', '450', '454', '460', '477', '48', '488', '49', '491', '492', '497', '4th', '50', '500', '501', '51', '518', '52', '53', '534', '549', '55', '550', '555', '55k', '56', '560', '57', '577', '58', '5th', '60', '600', '604', '605', '615', '62', '621', '63', '65', '650', '656', '657', '673', '68', '688', '69', '691', '6th', '70', '700', '7000', '702', '712', '736', '74', '75', '750', '76', '765', '767', '769', '76k', '77', '777', '79', '80', '800', '813', '814', '82', '83', '84', '848', '85', '850', '856', '86', '87', '870', '88', '880', '887', '895', '90', '900', '91', '925', '93', '94', '946', '950', '97', '98', '99', '997', 'aadhaar', 'aarti', 'ab', 'abate', 'abb', 'abfrl', 'able', 'absolutely', 'acc', 'accelerate', 'accord', 'account', 'accounting', 'accrual', 'accuse', 'achieve', 'acquire', 'acquisition', 'across', 'action', 'active', 'activity', 'acute', 'adani', 'add', 'address', 'adhesive', 'aditya', 'adityanath', 'administrator', 'adopt', 'adoption', 'adrian', 'advanced', 'advantage', 'advantaged', 'advice', 'advise', 'adviser', 'affect', 'affle', 'agam', 'agarwal', 'age', 'aggressively', 'agm', 'agrawal', 'agriculture', 'agrovet', 'ags', 'ahead', 'ahmad', 'aid', 'aim', 'air', 'airtel', 'aishwarya', 'aista', 'ajanta', 'ajay', 'akasa', 'alan', 'albinder', 'alembic', 'alkali', 'alkem', 'allcargo', 'allegation', 'allege', 'alleviate', 'allied', 'allocation', 'allotment', 'allow', 'ally', 'almost', 'alok', 'aluminium', 'amalgamation', 'amar', 'amara', 'amazon', 'amber', 'ambit', 'ambitious', 'ambuja', 'amc', 'amend', 'amendment', 'american', 'amid', 'amidst', 'amine', 'amit', 'among', 'amount', 'amp', 'analogy', 'analysis', 'analyst', 'analytic', 'anand', 'anantha', 'anchor', 'andrew', 'anil', 'announce', 'announcement', 'annual', 'annualise', 'annually', 'another', 'answer', 'ant', 'anti', 'anticipate', 'antique', 'anu', 'anupam', 'anurag', 'anything', 'anytime', 'apiece', 'apis', 'apollo', 'app', 'appeal', 'apple', 'application', 'apply', 'appoint', 'approach', 'appropriate', 'approval', 'approve', 'apr', 'april', 'arab', 'arabia', 'aramco', 'arbitrage', 'arbitration', 'arena', 'arm', 'arora', 'around', 'arpu', 'arrest', 'arrival', 'artisan', 'ascend', 'asdc', 'ash', 'ashmore', 'ashok', 'ashwin', 'ashwini', 'asia', 'asian', 'aside', 'ask', 'aspect', 'asset', 'asthma', 'astral', 'attack', 'attract', 'attractive', 'attrition', 'atul', 'au', 'audi', 'audit', 'august', 'aum', 'aurobindo', 'australia', 'authority', 'auto', 'automaker', 'automation', 'av', 'available', 'avendus', 'avenue', 'aviation', 'avoid', 'await', 'award', 'aware', 'awareness', 'away', 'axis', 'ayodhya', 'aziz', 'bachchan', 'back', 'bad', 'badly', 'badshah', 'baer', 'bag', 'bagger', 'bai', 'bajaj', 'bala', 'balaji', 'balance', 'balanced', 'balkrishna', 'ban', 'band', 'bandhan', 'bang', 'bangalore', 'bank', 'banker', 'banking', 'bankruptcy', 'bappi', 'barclay', 'bargain', 'baroda', 'barrel', 'base', 'basf', 'basis', 'bat', 'bata', 'batra', 'battery', 'bbl', 'bear', 'beat', 'beautiful', 'beauty', 'become', 'bee', 'begin', 'beginning', 'behemoth', 'behind', 'bel', 'believe', 'bell', 'benchmark', 'beneficiary', 'benefit', 'bengaluru', 'benign', 'berger', 'berkshire', 'bernstein', 'bet', 'beta', 'beverage', 'beware', 'beyond', 'bfsi', 'bhagya', 'bharat', 'bharatpe', 'bharti', 'bhattacharya', 'bhel', 'bhole', 'bid', 'bidding', 'biden', 'big', 'bikhchandani', 'bill', 'billion', 'billionaire', 'bima', 'bind', 'biocon', 'biologic', 'biosimilar', 'biotech', 'bipin', 'birla', 'birlasoft', 'biswa', 'bitcoin', 'biz', 'bizarrely', 'black', 'blanch', 'blast', 'blindly', 'block', 'blog', 'bloodbath', 'blower', 'blue', 'blw', 'bn', 'bnp', 'boaml', 'board', 'bob', 'bofa', 'bokor', 'bold', 'bolster', 'bomb', 'bombay', 'bond', 'bonus', 'book', 'booking', 'boom', 'boost', 'booster', 'borrow', 'borrowing', 'bosch', 'boss', 'bottle', 'bottom', 'bottomline', 'bottomwear', 'bounce', 'bourse', 'box', 'bpcl', 'brace', 'brand', 'breach', 'break', 'breakout', 'brent', 'brewery', 'bridge', 'bright', 'brightcom', 'bring', 'britannia', 'broad', 'broker', 'brokerage', 'bse', 'bse500', 'bubble', 'bucharest', 'budget', 'buffer', 'buffett', 'build', 'buildcon', 'bulk', 'bull', 'bulli', 'bullish', 'bump', 'bumper', 'burger', 'burn', 'business', 'bust', 'butterfly', 'buy', 'buyback', 'buyer', 'buying', 'buzz', 'ca', 'cabinet', 'cadila', 'cagr', 'cairn', 'cait', 'call', 'cam', 'canara', 'cancellation', 'canfin', 'cap', 'capacity', 'capex', 'capital', 'capitalisation', 'capt', 'captain', 'caravan', 'carbon', 'card', 'cardinally', 'care', 'careful', 'carry', 'case', 'cash', 'cashflow', 'cassette', 'catch', 'category', 'cause', 'caustic', 'caution', 'cautious', 'cbi', 'cci', 'cdp', 'cds', 'cea', 'ceat', 'ceiling', 'cement', 'central', 'centre', 'centrum', 'century', 'ceo', 'cera', 'ceremony', 'certain', 'cfo', 'cgd', 'chadha', 'chain', 'chairman', 'chakravarti', 'challenge', 'chambal', 'champion', 'change', 'charge', 'chart', 'charter', 'chartered', 'chaudhuri', 'cheap', 'check', 'cheer', 'chemical', 'chennai', 'chief', 'china', 'chintel', 'chip', 'chipmaker', 'chitra', 'choksi', 'cholamandalam', 'chopra', 'chouhan', 'christmas', 'cil', 'cinema', 'cipla', 'circuit', 'circulate', 'cite', 'citi', 'citicorp', 'citizen', 'city', 'claim', 'clean', 'clear', 'climate', 'climb', 'clinical', 'clip', 'clock', 'close', 'closing', 'cloud', 'clsa', 'club', 'clue', 'cm', 'cmd', 'cmo', 'cmr', 'cms', 'cnbc', 'co', 'coal', 'coaster', 'coffee', 'coforge', 'coinswitch', 'coke', 'cold', 'colgate', 'colocation', 'column', 'come', 'comeback', 'comfort', 'comment', 'commentary', 'commerce', 'commercialisation', 'commit', 'committee', 'commodity', 'common', 'communication', 'company', 'competition', 'competitive', 'competitor', 'complete', 'compliance', 'component', 'compounding', 'comstar', 'concall', 'concern', 'concerned', 'conclave', 'conclude', 'concor', 'condition', 'conduct', 'conference', 'confidence', 'confident', 'confidentially', 'confirm', 'conflict', 'confluence', 'congress', 'consider', 'consolidate', 'conspirator', 'constructive', 'consultation', 'consulting', 'consumer', 'consumption', 'contest', 'continue', 'continued', 'contraction', 'contribution', 'control', 'convenience', 'convenient', 'conversion', 'coo', 'cool', 'cop26', 'copper', 'core', 'coriander', 'corner', 'coromandel', 'corp', 'corporate', 'corporation', 'correction', 'cos', 'cost', 'costly', 'cotton', 'could', 'council', 'count', 'countdown', 'counter', 'country', 'couple', 'coupon', 'course', 'court', 'covaxin', 'coverage', 'covid', 'covishield', 'cpi', 'cr', 'crack', 'crash', 'craze', 'create', 'creation', 'creator', 'credit', 'creditaccess', 'cremate', 'cricket', 'crisil', 'crisis', 'criterion', 'crompton', 'crop', 'crore', 'cross', 'crosse', 'crucial', 'crude', 'crush', 'crypto', 'cryptocurrencie', 'cryptocurrency', 'cryptos', 'csb', 'cue', 'cummin', 'curb', 'curious', 'currency', 'current', 'cusp', 'customer', 'cut', 'cy22', 'cycle', 'cyclical', 'cyclically', 'cyient', 'cyril', 'da', 'dabur', 'dairy', 'dalal', 'dalmia', 'dance', 'das', 'dash', 'data', 'date', 'datum', 'day', 'db', 'dcb', 'deadline', 'deal', 'death', 'debt', 'debut', 'debutant', 'dec', 'decacorn', 'decade', 'december', 'decent', 'decision', 'decisively', 'declare', 'decline', 'decode', 'deepak', 'defaulter', 'defence', 'defend', 'defensive', 'defer', 'deficit', 'defining', 'defy', 'delay', 'delhi', 'delhivery', 'delightfully', 'delist', 'deliver', 'delivery', 'delta', 'demand', 'demat', 'demise', 'demographic', 'dengue', 'denial', 'denote', 'deora', 'depositary', 'depositor', 'depreciation', 'dept', 'deputy', 'der', 'derivative', 'deshmukh', 'design', 'despite', 'destroyer', 'detail', 'detect', 'deteriorate', 'deutsche', 'develop', 'developer', 'development', 'devyani', 'dhani', 'dhanlaxmi', 'dhantera', 'dhindsa', 'dhoot', 'diagnostic', 'dial', 'diamond', 'diary', 'didi', 'die', 'diesel', 'differential', 'differently', 'difficult', 'digest', 'digit', 'digital', 'digvijay', 'dilip', 'dilutive', 'dip', 'dipam', 'dipan', 'direct', 'director', 'disappoint', 'disappointing', 'disclosure', 'discount', 'discretionary', 'discuss', 'dish', 'disinvestment', 'dismiss', 'dismisse', 'dispatch', 'disposable', 'dispute', 'disruption', 'distribution', 'divestment', 'divi', 'division', 'divulge', 'diwali', 'dixon', 'dlf', 'dma', 'dmart', 'dodla', 'doha', 'dollar', 'domestic', 'dominant', 'dominic', 'dose', 'double', 'doultabad', 'dow', 'downgrade', 'downside', 'dr', 'draft', 'drag', 'drhp', 'drive', 'driver', 'driving', 'drop', 'drug', 'dsp', 'dubey', 'due', 'duggad', 'dumping', 'dunzo', 'duty', 'dvrs', 'dwarf', 'dwarikesh', 'early', 'earning', 'ease', 'east', 'eastern', 'easy', 'ebit', 'ebitda', 'eclerx', 'economic', 'economist', 'economy', 'ecosystem', 'ed', 'edelweiss', 'edge', 'edgile', 'edutech', 'edward', 'effect', 'effective', 'egm', 'egypt', 'eicher', 'eight', 'eke', 'ekta', 'election', 'electric', 'electrical', 'electronic', 'eligibility', 'elixir', 'elon', 'else', 'elss', 'elxsi', 'em', 'embed', 'emerge', 'emergency', 'emkay', 'emotional', 'employee', 'employment', 'emudhra', 'encouraging', 'end', 'endurance', 'energy', 'engineering', 'enjoy', 'enough', 'enter', 'enterprise', 'entertainment', 'enthusiasm', 'entire', 'entirely', 'entity', 'environment', 'environmental', 'envision', 'eois', 'ep', 'equipment', 'equitable', 'equity', 'erase', 'ergo', 'erode', 'escalate', 'escape', 'escort', 'esg', 'estate', 'estimate', 'etf', 'etfs', 'ethanol', 'ether', 'ethnic', 'euro', 'europe', 'ev', 'evacuate', 'evaluate', 'evasion', 'even', 'event', 'evergrande', 'every', 'evolution', 'ex', 'exaggerate', 'exceed', 'excise', 'excited', 'exciting', 'exclusive', 'execute', 'executive', 'exide', 'exit', 'expand', 'expansion', 'expect', 'expectation', 'expenditure', 'expensive', 'experience', 'expert', 'expiry', 'explain', 'explainer', 'explosion', 'export', 'exposure', 'express', 'extend', 'extremely', 'eye', 'fabindia', 'face', 'facebook', 'fact', 'factor', 'factory', 'fade', 'fail', 'fairly', 'fake', 'falguni', 'fall', 'fantastic', 'faq', 'faqs', 'far', 'fare', 'fargo', 'farm', 'farmer', 'fashion', 'fast', 'fat', 'fate', 'fda', 'fear', 'fearful', 'feb', 'february', 'fed', 'federal', 'fedfina', 'fee', 'feed', 'feel', 'ferrous', 'fertiliser', 'festive', 'fhrai', 'fiasco', 'ficci', 'fiem', 'fiera', 'fii', 'fiis', 'file', 'filing', 'fin', 'final', 'finance', 'financial', 'financing', 'fincorp', 'find', 'fine', 'finechem', 'finish', 'finmin', 'fino', 'finserv', 'fintech', 'fire', 'firm', 'first', 'firstsource', 'fiscal', 'fish', 'five', 'flag', 'flare', 'flat', 'flatline', 'flight', 'flirt', 'flow', 'fluorine', 'fluoro', 'fly', 'fm', 'fmcg', 'focus', 'follow', 'fomc', 'food', 'foodwork', 'fool', 'foot', 'footfall', 'footprint', 'foray', 'forecast', 'foreign', 'foresee', 'forge', 'forging', 'form', 'fortis', 'forward', 'founder', 'fpis', 'framework', 'franchise', 'francisco', 'fraud', 'free', 'fresh', 'fresher', 'friday', 'fs', 'fuel', 'full', 'fully', 'fund', 'fundamentally', 'funding', 'future', 'fy20', 'fy22', 'fy23', 'fy24', 'fy25', 'gaba', 'gagandeep', 'gail', 'gain', 'gainer', 'gallop', 'gandhi', 'gandhimathi', 'gap', 'gas', 'gasification', 'gathering', 'gati', 'gauge', 'gautam', 'gdp', 'gem', 'general', 'generate', 'generic', 'gently', 'geopolitical', 'geosphere', 'german', 'get', 'gets', 'getting', 'giant', 'gic', 'gift', 'gilt', 'gita', 'give', 'gjepc', 'glamm', 'glamorous', 'glance', 'glenmark', 'glitch', 'glitter', 'global', 'glut', 'gmm', 'gmo', 'gmp', 'gmr', 'gnfc', 'go', 'goa', 'godfrey', 'godrej', 'goenka', 'gold', 'goldilock', 'goldman', 'good', 'google', 'gopal', 'gopinath', 'gorakhpur', 'governance', 'government', 'governor', 'govt', 'grab', 'grade', 'gradual', 'gradually', 'grameen', 'grantham', 'granule', 'graph', 'grasim', 'gravity', 'great', 'greave', 'green', 'greenlam', 'grid', 'grill', 'grip', 'grofer', 'gross', 'ground', 'group', 'grow', 'growth', 'gsfc', 'gst', 'guarantee', 'guard', 'gubbi', 'guidance', 'guideline', 'gujarat', 'gupta', 'guru', 'guv', 'h1', 'h1fy23', 'h2', 'h2fy22', 'hai', 'hair', 'hal', 'half', 'halt', 'hand', 'handle', 'happy', 'harbinger', 'hardeep', 'harris', 'harsh', 'hathaway', 'havell', 'hawkish', 'hc', 'hcl', 'hdfc', 'head', 'headroom', 'headwind', 'health', 'healthcare', 'healthy', 'heart', 'heavy', 'hedge', 'heg', 'heighten', 'help', 'herald', 'hero', 'hfcl', 'hide', 'high', 'higher', 'highlight', 'hike', 'hindalco', 'hinduja', 'hindustan', 'hint', 'hire', 'history', 'hit', 'hithe', 'hnis', 'hold', 'holder', 'holding', 'holiday', 'holland', 'home', 'homebuyer', 'honeywell', 'hope', 'hopeful', 'hopefully', 'hospital', 'hot', 'hotel', 'hound', 'house', 'housing', 'hover', 'hp', 'hpcl', 'hsbc', 'hudco', 'huge', 'hul', 'human', 'hunt', 'hurdle', 'hurt', 'hut', 'hydrogen', 'icici', 'idbi', 'idea', 'ideally', 'identity', 'idfc', 'iex', 'ifgl', 'igidr', 'igl', 'iifl', 'iit', 'il', 'illiquid', 'imagine', 'imf', 'immediate', 'imminent', 'immunity', 'impact', 'import', 'importance', 'important', 'impose', 'imposition', 'impressive', 'improve', 'improvement', 'inc', 'incentive', 'inch', 'income', 'increase', 'incredible', 'indecisiveness', 'index', 'india', 'indiabull', 'indiamart', 'indian', 'indicate', 'indice', 'indigo', 'indo', 'indraprastha', 'indus', 'indusind', 'industry', 'infina', 'inflation', 'inflow', 'influence', 'info', 'infocomm', 'inform', 'information', 'infosy', 'infotech', 'infra', 'infrastructure', 'infratech', 'infy', 'ingovern', 'ingram', 'initial', 'initiate', 'injection', 'inmobi', 'innovation', 'inox', 'input', 'inside', 'insider', 'insolvency', 'instant', 'institute', 'institutional', 'instl', 'insurance', 'intact', 'intellect', 'intense', 'interest', 'interested', 'interglobe', 'internal', 'international', 'internet', 'intervention', 'interview', 'introduce', 'invade', 'invasion', 'inventory', 'invesco', 'invest', 'investec', 'investigation', 'investing', 'investment', 'investor', 'invite', 'ioc', 'iol', 'ipca', 'ipo', 'ipos', 'iran', 'irb', 'irctc', 'irdai', 'irfc', 'iron', 'isma', 'ispat', 'issue', 'itc', 'itr', 'ixigo', 'jack', 'jahangir', 'jai', 'jaidev', 'jain', 'jan', 'january', 'jayant', 'jb', 'jeevan', 'jefferie', 'jerome', 'jewellery', 'jhujhunwala', 'jhunjhunwala', 'jindal', 'jio', 'jk', 'jm', 'job', 'join', 'joshi', 'jostle', 'journey', 'jp', 'jpc', 'jpmorgan', 'jspl', 'jsw', 'jubilant', 'julius', 'jump', 'june', 'justify', 'juxtapose', 'jv', 'kabeer', 'kabir', 'kalyan', 'kamala', 'kamath', 'kang', 'kansai', 'kapur', 'kaveri', 'keep', 'kela', 'kerala', 'key', 'kfc', 'khaitan', 'khemka', 'kick', 'kid', 'kill', 'kim', 'king', 'kiran', 'kirloskar', 'kishore', 'kitty', 'know', 'kohli', 'kotak', 'krishna', 'kryptoin', 'kuber', 'kumar', 'kunal', 'lab', 'lady', 'lagging', 'lahiri', 'lakh', 'lakshmi', 'lal', 'land', 'lanreotide', 'lap', 'large', 'largecap', 'largely', 'larsen', 'last', 'late', 'latent', 'launch', 'laurus', 'law', 'lawsuit', 'lay', 'lead', 'leader', 'leak', 'learn', 'leave', 'leg', 'legalise', 'leisure', 'lemon', 'lend', 'lending', 'less', 'let', 'letter', 'level', 'lever', 'leyland', 'liberalise', 'lic', 'life', 'lifescience', 'lifetime', 'lift', 'light', 'lightweight', 'like', 'likely', 'limelight', 'limit', 'linde', 'line', 'linear', 'linger', 'link', 'liquidate', 'liquidity', 'list', 'listing', 'litre', 'little', 'live', 'lkp', 'lme', 'lng', 'loan', 'lock', 'lockdown', 'lofty', 'log', 'logistic', 'lok', 'lombard', 'long', 'look', 'looks', 'loom', 'lose', 'loser', 'losing', 'loss', 'lot', 'low', 'lower', 'lt', 'ltd', 'lukewarm', 'lump', 'lupin', 'luthra', 'macquarie', 'macro', 'macrotech', 'mad', 'madhur', 'madhuri', 'mage', 'mahadevan', 'mahindra', 'main', 'maintain', 'major', 'majority', 'make', 'maker', 'making', 'mall', 'mallya', 'mamedi', 'man', 'manage', 'management', 'manager', 'manappuram', 'mania', 'manike', 'mantra', 'manufacturing', 'manulife', 'many', 'mapmyindia', 'marcellus', 'march', 'margin', 'marginal', 'marginally', 'marico', 'mark', 'market', 'marketbuzz', 'marketing', 'marriage', 'mart', 'martin', 'maruti', 'masayashi', 'massive', 'massively', 'material', 'matter', 'matthews', 'max', 'may', 'mayuresh', 'mc', 'mcap', 'mcguire', 'mcx', 'md', 'mean', 'meaty', 'mechanism', 'medicine', 'medium', 'medplus', 'meet', 'meeting', 'meghmani', 'mehta', 'merely', 'merger', 'message', 'meta', 'metal', 'metaverse', 'meteoric', 'metlife', 'metro', 'metropolis', 'mf', 'mfs', 'mgl', 'mgnrega', 'midcap', 'mideast', 'might', 'mihir', 'mild', 'mile', 'mill', 'million', 'mimic', 'mind', 'minda', 'mindspace', 'mindtree', 'mine', 'mining', 'minister', 'minute', 'mirae', 'mirza', 'mishra', 'miss', 'mistake', 'mitessh', 'mittal', 'mix', 'mixed', 'mn', 'mobikwik', 'mobility', 'mode', 'model', 'modest', 'modi', 'moeli', 'mofsl', 'moil', 'moment', 'momentum', 'momentumiser', 'monarch', 'monday', 'monetary', 'monetisation', 'money', 'moneycontrol', 'monitor', 'month', 'monthly', 'moody', 'morgan', 'morning', 'morse', 'mortgage', 'motherson', 'motilal', 'moto', 'motocorp', 'motor', 'motorcorp', 'mount', 'mourn', 'move', 'mowat', 'mpc', 'mphasis', 'mr', 'mrf', 'msp', 'mt', 'much', 'muhurat', 'mukherjea', 'mull', 'multi', 'multiple', 'multipli', 'mumbai', 'mundra', 'musk', 'must', 'mute', 'muted', 'muthoot', 'mutual', 'mylan', 'mysterious', 'myth', 'nabard', 'nadir', 'nadu', 'nageswaran', 'nalco', 'naren', 'narne', 'nasal', 'nasdaq', 'nashik', 'natco', 'national', 'nato', 'natural', 'nature', 'navigate', 'navin', 'navratri', 'nayar', 'nazara', 'nbcc', 'nbfc', 'nbfcs', 'nclat', 'ndtv', 'near', 'nearly', 'need', 'neelachal', 'neelkanth', 'negative', 'neil', 'neither', 'nerolac', 'nervous', 'nestle', 'net', 'network', 'networth', 'neutral', 'neutralise', 'never', 'new', 'newly', 'news', 'next', 'nfos', 'nhai', 'niche', 'nickel', 'nifty', 'nifty200', 'nifty50', 'nifty500', 'nigam', 'niif', 'niit', 'nikhil', 'nilesh', 'nipah', 'nippon', 'nirav', 'nirmal', 'nithin', 'nitin', 'nitrite', 'nlc', 'nmdc', 'no', 'nod', 'nomination', 'nomura', 'non', 'norm', 'nosedive', 'notch', 'note', 'notice', 'notifie', 'nov', 'november', 'nse', 'ntpc', 'nuclear', 'number', 'nykaa', 'nykka', 'nyse', 'oak', 'oberoi', 'occupation', 'oct', 'october', 'odi', 'oe', 'offer', 'official', 'offload', 'ofs', 'oil', 'ola', 'old', 'olivo', 'oman', 'omicron', 'one', 'one97', 'oneplus', 'ongc', 'onion', 'onwards', 'opec', 'open', 'opening', 'operate', 'operating', 'operator', 'oppo', 'opportunity', 'opt', 'optimistic', 'option', 'order', 'orderbook', 'ore', 'organic', 'orient', 'oswal', 'ott', 'outcome', 'outlook', 'outperform', 'outperforming', 'output', 'outright', 'outshine', 'outstanding', 'outweigh', 'overextend', 'overhaul', 'overnight', 'overseas', 'overweight', 'owner', 'ownership', 'oyo', 'pace', 'pack', 'package', 'pact', 'page', 'paharia', 'pain', 'paint', 'paintmaker', 'paisa', 'paise', 'pakistan', 'palm', 'palmolive', 'pandemic', 'pandora', 'panel', 'panic', 'paper', 'paradiso', 'paras', 'parekh', 'paribas', 'park', 'parl', 'parliament', 'partial', 'participate', 'participation', 'partner', 'party', 'pass', 'passive', 'past', 'pat', 'path', 'pathak', 'patil', 'patnaik', 'pattern', 'paul', 'pause', 'pay', 'payment', 'payroll', 'paytm', 'pb', 'pd', 'pe', 'peak', 'peer', 'pen', 'penalise', 'penetration', 'people', 'per', 'percent', 'perform', 'performance', 'performer', 'period', 'persistent', 'personal', 'perspective', 'pet', 'peter', 'petrol', 'petroleum', 'petronet', 'pfaudler', 'pfc', 'pfizer', 'pfrda', 'pfutp', 'pgim', 'pharma', 'phase', 'phenomenal', 'phenomenally', 'philippine', 'phoenix', 'pi', 'pick', 'picture', 'pidilite', 'pig', 'pill', 'pilot', 'pin', 'pine', 'pipeline', 'piramal', 'pitch', 'pizza', 'place', 'placement', 'plan', 'platform', 'platt', 'play', 'playbook', 'player', 'plea', 'plenty', 'pli', 'plot', 'plunge', 'pm', 'pmc', 'pnb', 'pnc', 'pocket', 'podcast', 'point', 'poise', 'policy', 'policybazaar', 'political', 'poll', 'ponzi', 'poonawalla', 'poor', 'poorly', 'popular', 'popularity', 'populist', 'port', 'portfolio', 'portion', 'position', 'positive', 'positively', 'possibility', 'possible', 'post', 'postcard', 'potential', 'pound', 'powell', 'power', 'powergrid', 'pr', 'practice', 'pradhan', 'prakash', 'pramod', 'prasad', 'prashant', 'prataap', 'pratik', 'pratip', 'pre', 'precious', 'precision', 'prefer', 'preferential', 'premium', 'premiumisation', 'prepaid', 'preparation', 'prepare', 'prepay', 'pressure', 'prestige', 'prevent', 'prevention', 'preview', 'previous', 'price', 'pricing', 'prime', 'private', 'priyanka', 'pro', 'probe', 'probis', 'proceed', 'process', 'product', 'production', 'profile', 'profit', 'profitability', 'profitable', 'profitably', 'program', 'progress', 'project', 'promise', 'promote', 'promoter', 'property', 'prophet', 'proposal', 'prospect', 'prospectus', 'protection', 'protest', 'prove', 'provider', 'proxy', 'pru', 'prudential', 'psu', 'psus', 'psyche', 'pt', 'ptc', 'public', 'pull', 'pullback', 'pulmatrix', 'pump', 'pune', 'punjab', 'purchase', 'puri', 'push', 'put', 'putin', 'pv', 'pvr', 'q1', 'q2', 'q2cy22', 'q2fy22', 'q2fy23', 'q3', 'q3cy21', 'q3fy22', 'q3fy23', 'q4', 'qib', 'qoq', 'qtrs', 'quality', 'quarantine', 'quarter', 'quarterly', 'question', 'quick', 'quit', 'quo', 'raamdeo', 'radico', 'rahul', 'rai', 'raid', 'railtel', 'railway', 'rain', 'raise', 'raja', 'rajasthan', 'rajiv', 'rajneesh', 'rajnish', 'rajya', 'rakesh', 'rally', 'ramakrishna', 'ramco', 'ramdeo', 'ramkrishna', 'range', 'rangebound', 'rasayan', 'rate', 'rategain', 'rather', 'rathi', 'rating', 'rattle', 'ravi', 'raw', 'rawat', 'raymond', 'rbi', 'rbl', 'rcap', 'rcf', 'reach', 'react', 'reaction', 'read', 'ready', 'real', 'reality', 'realty', 'reap', 'reason', 'reasonable', 'reasonably', 'reassure', 'rebalance', 'rebalancing', 'rebound', 'rec', 'receipt', 'receive', 'recent', 'reclaim', 'recognise', 'recognition', 'recommend', 'record', 'recoup', 'recover', 'recovery', 'red', 'reddy', 'reduce', 'reduction', 'reel', 'reema', 'refer', 'refined', 'refinerie', 'reflect', 'reflection', 'refractory', 'refute', 'regain', 'region', 'regulate', 'regulation', 'regulatory', 'reiterate', 'reject', 'rejig', 'relate', 'related', 'relation', 'release', 'reliance', 'relief', 'remain', 'renew', 'rent', 'reopen', 'repay', 'repeal', 'replace', 'repo', 'report', 'repositioning', 'request', 'requirement', 'rerating', 'rescue', 'research', 'reserve', 'resistance', 'resolve', 'respect', 'respond', 'response', 'responsible', 'restaurant', 'restrain', 'restriction', 'restructure', 'result', 'resultant', 'resume', 'resuscitation', 'retail', 'retain', 'retaliation', 'retention', 'retirement', 'retreat', 'retro', 'retrospective', 'return', 'revenue', 'reverse', 'review', 'revision', 'revisit', 'revival', 'revlimid', 'revoke', 'reward', 'rewind', 'rewinde', 'rice', 'rich', 'ride', 'right', 'ril', 'rise', 'risk', 'road', 'roar', 'robust', 'robustly', 'rohan', 'rohit', 'roller', 'room', 'rossari', 'round', 'row', 'rs', 'rubber', 'rule', 'run', 'rupee', 'rural', 'rush', 'russia', 'russian', 'sabha', 'sach', 'safe', 'saga', 'sahi', 'sail', 'saksoft', 'salary', 'sale', 'salil', 'salzer', 'sambre', 'samir', 'samvat', 'sanction', 'sandip', 'sanford', 'sanguine', 'sania', 'sanitaryware', 'sanjeev', 'sansera', 'sapphire', 'saudi', 'saurabh', 'savvy', 'say', 'sbi', 'sc', 'scale', 'scam', 'scandal', 'scare', 'schaeffler', 'schedule', 'scheme', 'science', 'scooter', 'screenshot', 'scrip', 'season', 'sebi', 'sec', 'second', 'secretary', 'sector', 'sectoral', 'security', 'secy', 'see', 'seed', 'seek', 'seeks', 'segment', 'select', 'selection', 'sell', 'seller', 'selling', 'selloff', 'semiconductor', 'sen', 'send', 'sense', 'sensex', 'sentiment', 'sentimeter', 'sep', 'sept', 'september', 'series', 'seriously', 'serum', 'service', 'session', 'set', 'settle', 'settlement', 'setup', 'seven', 'severe', 'sfb', 'sgx', 'shah', 'shaktikanta', 'shanghai', 'shankar', 'shaped', 'share', 'shareholde', 'shareholder', 'sharing', 'sharma', 'sharp', 'sharply', 'shaw', 'shed', 'shekhar', 'shelter', 'shenoy', 'sheth', 'shift', 'shine', 'shipping', 'shiprocket', 'shock', 'shockwave', 'shoot', 'short', 'shortage', 'shortlist', 'shot', 'shoulder', 'show', 'shree', 'shrikant', 'shriram', 'shroff', 'shrug', 'shy', 'sidbi', 'side', 'siemen', 'sigachi', 'sight', 'sign', 'signal', 'significant', 'silver', 'since', 'sind', 'singapore', 'singh', 'singhania', 'single', 'sinha', 'sink', 'sip', 'sit', 'sitharaman', 'situation', 'six', 'size', 'sjs', 'sjvn', 'skid', 'skip', 'slap', 'slash', 'slide', 'slip', 'slow', 'slump', 'small', 'smallcap', 'smart', 'smoothly', 'snack', 'snap', 'snapdeal', 'sneeze', 'soar', 'sobha', 'soda', 'soft', 'softbank', 'soften', 'solar', 'solara', 'solution', 'somanathan', 'sombre', 'something', 'somsundaram', 'son', 'sona', 'sonia', 'sony', 'soon', 'soothe', 'sop', 'sound', 'source', 'space', 'spandana', 'spark', 'special', 'specialised', 'specialty', 'speech', 'speed', 'spend', 'spending', 'sphoorty', 'spicejet', 'spike', 'spin', 'spinner', 'spirit', 'spook', 'spooking', 'spot', 'spotlight', 'spray', 'spread', 'spree', 'srf', 'srivastava', 'st', 'stability', 'staffing', 'stage', 'stagflation', 'stainless', 'stake', 'stall', 'stance', 'standard', 'stanley', 'staple', 'star', 'starbuck', 'start', 'startup', 'state', 'statement', 'status', 'stay', 'steady', 'steam', 'steel', 'steep', 'step', 'sterling', 'stick', 'stiff', 'still', 'stimulus', 'stock', 'stockpile', 'stone', 'stop', 'store', 'story', 'stovekraft', 'straight', 'strain', 'strand', 'strategic', 'strategy', 'streak', 'street', 'strength', 'strengthen', 'stretch', 'strike', 'strive', 'strong', 'structural', 'struggle', 'stuck', 'sub', 'subdue', 'subpoena', 'subramanian', 'subscribe', 'subscriber', 'subscription', 'subside', 'subsidiary', 'successful', 'sucker', 'sudarshan', 'sudden', 'sue', 'suffer', 'suffocate', 'sugar', 'suggest', 'suisse', 'sukhani', 'sum', 'sumi', 'summer', 'summit', 'summon', 'sun', 'sundaram', 'sunil', 'sunteck', 'super', 'superior', 'supermart', 'supply', 'support', 'supportive', 'supriya', 'sure', 'surge', 'surpass', 'surplus', 'surprise', 'survey', 'survive', 'survivor', 'sushmita', 'suspend', 'sustain', 'sustainable', 'suumaya', 'suzuki', 'swamy', 'swiggy', 'swing', 'syngene', 'syngle', 'system', 'tablet', 'tackle', 'taher', 'take', 'talk', 'tamil', 'tank', 'tanla', 'tantrum', 'tap', 'taper', 'target', 'tariff', 'tarson', 'tata', 'tax', 'taxation', 'taxis', 'tcs', 'teamlease', 'tear', 'tech', 'techm', 'technical', 'technology', 'teen', 'tega', 'tejas', 'telco', 'telecom', 'telegram', 'teleservice', 'tell', 'temper', 'tendulkar', 'tension', 'tepid', 'term', 'termination', 'territory', 'tesla', 'test', 'texas', 'textile', 'thakkar', 'theme', 'theory', 'therapy', 'thicken', 'thing', 'third', 'threat', 'thrust', 'thumb', 'thursday', 'tie', 'tight', 'tighten', 'till', 'tiller', 'time', 'timex', 'tip', 'titan', 'today', 'tokenisation', 'tomorrow', 'tonne', 'top', 'torrent', 'total', 'toubro', 'touch', 'tough', 'towards', 'tower', 'tpg', 'track', 'traction', 'tractor', 'trade', 'trader', 'trading', 'traditional', 'train', 'trajectory', 'transact', 'transaction', 'transmissibility', 'transmissible', 'transplant', 'transport', 'travel', 'treatment', 'tree', 'tremendous', 'trend', 'trent', 'trial', 'trident', 'trigger', 'trillion', 'trim', 'trivedi', 'troop', 'trouble', 'true', 'truecaller', 'trust', 'ttk', 'tuesday', 'tug', 'tulip', 'tumble', 'turmoil', 'turn', 'turnout', 'tushar', 'tussle', 'tv', 'tv18', 'tvs', 'tweet', 'twin', 'twitter', 'two', 'tyre', 'uae', 'ub', 'uday', 'ugro', 'ujjivan', 'uk', 'ukraine', 'ultratech', 'umbrella', 'uncertainty', 'unchanged', 'underlie', 'undermine', 'underperform', 'underperformance', 'underwriter', 'unfold', 'unfortunate', 'unichem', 'unicorn', 'uniform', 'unilever', 'union', 'unit', 'united', 'unless', 'unlikely', 'unnerve', 'unregulated', 'upbeat', 'upcoming', 'upcycle', 'update', 'upgrade', 'upl', 'upper', 'upside', 'uptick', 'upward', 'urge', 'usage', 'usd', 'use', 'user', 'usfda', 'usha', 'usl', 'uti', 'utilisation', 'va', 'vaccination', 'vague', 'vahan', 'vaishnaw', 'vakil', 'valkyrie', 'valuation', 'value', 'vampire', 'van', 'vandana', 'vardhman', 'variant', 'various', 'varun', 'vast', 'vcs', 'vedant', 'vedanta', 'vehicle', 'venkatraman', 'ventura', 'venture', 'venugopal', 'verma', 'versus', 'vertical', 'vested', 'vi', 'via', 'videocon', 'vidhata', 'view', 'vijay', 'vinit', 'violation', 'vip', 'virat', 'virus', 'visibility', 'vision', 'vix', 'vk', 'vlcc', 'vodafone', 'voice', 'volatile', 'volatility', 'volta', 'volume', 'vora', 'vote', 'voter', 'voting', 'vr', 'vs', 'vst', 'vulnerable', 'wabag', 'wait', 'wall', 'wallet', 'wane', 'war', 'warn', 'warning', 'warrant', 'warren', 'wary', 'watch', 'wave', 'way', 'weak', 'weaken', 'weakness', 'wealth', 'wealthy', 'wear', 'wednesday', 'week', 'weekend', 'weekendinvesting', 'weekly', 'weigh', 'well', 'wellness', 'western', 'wheeler', 'whistle', 'whistleblow', 'white', 'whole', 'wholesale', 'wild', 'william', 'wilmar', 'wilson', 'win', 'windlas', 'wing', 'winner', 'winning', 'winter', 'wipe', 'wipro', 'wishlist', 'withdraw', 'without', 'witness', 'wo', 'wockhardt', 'woe', 'woman', 'wonderla', 'work', 'workweek', 'world', 'worried', 'worry', 'worst', 'worth', 'worthy', 'would', 'wpi', 'wrap', 'xiaomi', 'xm', 'year', 'yen', 'yes', 'yesterday', 'yet', 'yield', 'yogi', 'yoy', 'yr', 'ys', 'zee', 'zeel', 'zero', 'zerodha', 'zinc', 'zomato', 'zone', 'zoom']\n"
     ]
    }
   ],
   "source": [
    "def text_representation(data):\n",
    "  tfidf_vect = TfidfVectorizer()\n",
    "  data['text'] = data['text'].apply(lambda text: \" \".join(set(text)))\n",
    "  data['text'].to_csv(\"data_file.csv\")\n",
    "  X_tfidf = tfidf_vect.fit_transform(data['text'])\n",
    "  #print(type(X_tfidf))\n",
    "  print(X_tfidf.shape)\n",
    "  print(tfidf_vect.get_feature_names())\n",
    "  X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "  return X_tfidf\n",
    "#apply the TFIDV function\n",
    "X_tfidf = text_representation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model Training: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3039</th>\n",
       "      <th>3040</th>\n",
       "      <th>3041</th>\n",
       "      <th>3042</th>\n",
       "      <th>3043</th>\n",
       "      <th>3044</th>\n",
       "      <th>3045</th>\n",
       "      <th>3046</th>\n",
       "      <th>3047</th>\n",
       "      <th>3048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2065 rows × 3049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  3039  \\\n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "2060   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2061   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2062   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2063   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2064   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "      3040  3041  3042  3043  3044  3045  3046  3047  3048  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2060   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2061   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2062   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2063   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2064   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2065 rows x 3049 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04        48\n",
      "           1       0.93      1.00      0.96       634\n",
      "\n",
      "    accuracy                           0.93       682\n",
      "   macro avg       0.97      0.51      0.50       682\n",
      "weighted avg       0.94      0.93      0.90       682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X= X_tfidf\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#fit Log Regression Model\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3039</th>\n",
       "      <th>3040</th>\n",
       "      <th>3041</th>\n",
       "      <th>3042</th>\n",
       "      <th>3043</th>\n",
       "      <th>3044</th>\n",
       "      <th>3045</th>\n",
       "      <th>3046</th>\n",
       "      <th>3047</th>\n",
       "      <th>3048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 3049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8        9     ...  \\\n",
       "1333   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.26647  ...   \n",
       "1963   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "1335   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "1326   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "29     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...      ...  ...   \n",
       "1923   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "358    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "2054   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "236    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "551    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.00000  ...   \n",
       "\n",
       "      3039  3040  3041  3042  3043  3044  3045  3046  3047  3048  \n",
       "1333   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1963   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1335   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1326   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "29     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1923   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "358    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2054   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "236    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "551    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[682 rows x 3049 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3238    1\n",
       "4730    1\n",
       "3244    1\n",
       "3223    1\n",
       "72      1\n",
       "       ..\n",
       "4649    1\n",
       "941     1\n",
       "4972    1\n",
       "614     1\n",
       "1427    1\n",
       "Name: label, Length: 682, dtype: int32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 predict new headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"These 2 stocks help Rakesh Jhunjhunwala get richer by Rs 861 crore in just 1 day\"]\n",
    "tf = TfidfVectorizer()\n",
    "tfdf = tf.fit_transform(data['text'])\n",
    "vect = pd.DataFrame(tf.transform(new_data).toarray())\n",
    "new_data = pd.DataFrame(vect)\n",
    "logistic_prediction = clf.predict(new_data)\n",
    "print(logistic_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Store the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = pickle.dumps(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_from_pickle = pickle.loads(logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_from_pickle.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('logistic_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('logistic_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310850439882697\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
